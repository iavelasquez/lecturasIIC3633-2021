<b>Lectura Semana 3:</b>  
<i>Guy, S., & Gunawardana, A.. (2011) “Evaluating recommendation systems.” In Recommender systems handbook, pp. 257-297. Springer US, 2011.</i>

El artículo presentado compara tres estrategias distintas utilizadas para evaluar sistemas recomendadores. Específicamente, estas estrategias son: (i) experimentos fuera de línea basados en conjuntos de datos y modelado del comportamiento de los usuarios; (ii) estudios de usuarios; y (iii) experimentos en línea que evalúan el comportamiento de los sistemas sobre usuarios reales. Si bien podrían existir otras estrategias, el artículo argumenta adecuadamente la decisión de enfocarse en estas tres debido a que son las utilizadas en otras áreas de áreas relacionadas, como aprendizaje de máquinas.

La comparación es realizada en base a un conjunto de propiedades que podrían ser relevantes para los sistemas recomendadores. Este enfoque le parece adecuado al lector, pues, como se comenta en el mismo artículo, en los sistemas recomendadores no importa únicamente su precisión al momento de recomendar, si no que existen otras características, tales como la privacidad y los tiempos de espera, que también son importantes para los usuarios.

La estrategia de análisis seguida en el artículo es bien explicada y aplicada. Finalmente, el lector queda con la noción de que cada una de las distintas estrategias analizadas posee distintas ventajas y desventajas sobre las otras, siendo así más o menos útiles según las propiedades que se deseen evaluar.

Un punto negativo del artículo es que las conclusiones presentadas son demasiado concisas. Una forma en la que el lector siente que se podría haber mejorado el cierre del artículo es incluyendo una sección de discusiones finales, donde se presentara una tabla que resumiera el análisis realizado sobre las distintas propiedades y estrategias de evaluación, facilitando así la comprensión de lo expuesto previamente.
